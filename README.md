# SigmaSenseJp
経験を通じて自らスキルを獲得し、成長していく知的エージェントを目指しています。

## クイックスタート

本プロジェクトをセットアップし、実行するための手順は以下の通りです。Python 3.9以上を推奨します。

### 1. リポジトリのクローン
```bash
git clone https://github.com/user/SigmaSenseJp.git
cd SigmaSenseJp
```

### 2. 仮想環境の構築と有効化
```bash
python -m venv venv
source venv/bin/activate
```

### 3. 依存ライブラリのインストール
```bash
pip install -r requirements.txt
```
`ja-ginza`のインストール中にエラーが発生した場合は、先に`spacy`と`ginza`をインストールしてから再度試してください。
```bash
pip install spacy ginza
pip install -r requirements.txt
```

### 4. APIキーの設定
本システムはGemini APIを使用します。環境変数にAPIキーを設定してください。
```bash
export GEMINI_API_KEY="YOUR_API_KEY"
```

### 5. 実行
メインの思考サイクルを実行するには、以下のコマンドを実行します。
```bash
python scripts/run_sigma.py
```

# Project Realize: 自己進化型意味照合システム

## 1. 基本設計思想：SigmaSenseとは何か

SigmaSenseは、単なる画像照合システムではなく、**経験を通じて自らスキルを獲得し、成長していく知的エージェント**である。その核心は、ルールベースの**演繹的推論**（Symbolic）と、AIによる**帰納的設計**（Neuro）を組み合わせた、独自のニューロシンボリック・アーキテクチャにある。

### 1.1. ハイブリッドAIアーキテクチャ
SigmaSenseのアーキテクチャは、二つの異なる知性の協調によって成立しています。

- **意味の設計者（帰納エンジン）**: Gemini APIに代表される大規模言語モデル（通称「オリエン大賢者」）が、人間との対話や高度な推論を通じて、システムの「ものさし」となる意味次元そのものを設計・提案します。これは、未知のデータから新たな知識やパターンを見出す帰納的なプロセスです。

- **意味の実行者（演繹エンジン）**: `vector_generator`や`sigma_sense`などのモジュール群が、設計された意味次元に基づき、厳密なルールで意味ベクトルを計算・照合します。**このエンジンが純粋な生成AIと一線を画すのは、その動作原理が数学的・物理学的理論に裏打ちされている点です。**

#### 1.1.1. 演繹エンジンの理論的基盤
演繹エンジンは、曖昧さを排した数学的・物理学的理論に基づいて意味ベクトルを計算します。主な理論的基盤は以下の通りです。

- **構造幾何学 (Structural Geometry)**: Huモーメント不変量などを用いて、回転・スケール等に不変な形状特徴を抽出します。
- **線形代数 (Linear Algebra)**: 特徴をベクトル空間に写像し、コサイン類似度などで意味的な近さを測ります。
- **情報理論 (Information Theory)**: シャノンエントロピーなどを用いて、ベクトルが持つ情報量を定量化します。
- **圏論 (Category Theory)**: 関手性の概念を用いて、システムの操作が論理的な一貫性を持つことを保証します。
- **層理論 (Sheaf Theory)**: 局所的な特徴を矛盾なく結合し、大域的な特徴を導出します。
- **群化理論 (Grouping Theory)**: 形状の不変性を利用して、画像内のオブジェクト群を認識します。

本プロジェクトのアーキテクチャと理論的背景に関する詳細な情報は、以下のドキュメントにまとめています。

> **[📄 技術スタックと設計思想](./doc/technology_stack.md)**  
> 本プロジェクトで採用している主要な技術（Gemini, Ollama, TensorFlow, OpenCV等）の役割と、それらを組み合わせる設計思想について説明します。
> 
> **[📄 理論的基盤と実装の詳細](./doc/mathematical_foundations.md)**  
> 演繹エンジンを支える各理論（構造幾何学、圏論、層理論など）の数学的定義と、コードレベルでの具体的な実装について詳述します。

---

### 1.1.2. 定量的評価

本プロジェクトの性能は、以下のタスクと指標によって定量的に評価されます。

- **タスク例**:
  - **幾何学図形の識別**: `sigma_images` 内の基本的な図形（円、四角形など）を正しく識別できるか。
  - **犬種の分類**: `config/terrier_prompt.txt` で定義された特徴を用いて、ノーフォークテリアとケアーンテリアの画像を分類できるか。
  - **論理的一貫性の維持**: `tools/functor_consistency_checker.py` を実行し、意図しない副作用なしにデータベースが安定しているか。

- **評価指標**:
  - **分類精度 (Accuracy)**: 上記の分類タスクにおいて、正しく分類された画像の割合。
    ```
    Accuracy = (True Positives + True Negatives) / Total Samples
    ```
  - **関手性一貫性率 (Functorial Consistency Rate)**:
    `functor_consistency_checker.py` のテストにおいて、副作用（予期せぬ次元の変化）が発生しなかったテストケースの割合。
    ```
    Consistency Rate = 1 - (Number of Failed Cases / Total Test Cases)
    ```
  - **情報量基準**: KLダイバージェンスやワッサースタイン距離を用いて、2つの意味ベクトルの分布間の「距離」を測定し、照合の確信度とします。



### 1.2. 主要な能力と特徴
1.  **データ主導の自己拡張**:
    SigmaSenseの進化は、原則としてソースコードの変更ではなく、「データ」の追加によって行われます。新たな概念は新しい「意味次元」として、知識は「意味データベース」のエントリとして追加されます。これにより、オフライン環境のような厳しい制約下でも、新たなデータ（次元定義や観測データ）を取り込むだけで進化を続けることができます。システムの振る舞いを根本的に変える必要がある場合にのみ、ステージ2の「即興」プロセスが作動し、セキュアなサンドボックス環境で新しいコードが実行されます。この「原則データ、例外コード」という設計思想が、システムの安定性と柔軟な拡張性を両立させています。

2.  **多層的な意味空間**:
    認識対象に応じて「幾何学図形（Seliaレイヤー）」や「生物・複雑形状（Lyraレイヤー）」など、異なる意味空間を使い分ける。これにより、猫と円を比較するような無意味な照合を自ら棄却し、文脈に応じた高精度な認識を実現する。

3.  **デュアル・インテリジェンス**:
    - **オンライン知性（オリエン）**: 高度なLLMを活用し、全体最適化された意味次元のマスタープランを設計する。
    - **オフライン知性（ヴェトラ）**: 通信が途絶した環境でも、内蔵LLMとOpenCVで自律的に新たな意味次元を発見・学習し、環境に適応する。

4.  **全自動自己拡張ループ（第十四次実験にて完成）**:
    未知のタスク（学習目標）に対し、人間の介入を一切必要とせず、完全に自律して新たなスキルを獲得・恒久化する。
    - **ステージ1: 即応 (Immediate Response)**: 既知のタスクを、事前に登録された恒久ハンドラで即座に処理する。
    - **ステージ2: 即興と自己生成 (Improvisation & Self-Generation)**: 未知のタスクに遭遇した際、オフライン知性「ヴェトラ」が、内蔵されたコード生成LLM（`codegemma`）を用いて、そのタスクを解決するための臨時ハンドラコードを**自律的に生成**する。生成されたコードは、安全なサンドボックス環境で即座に実行され、タスク達成が試みられる。
    - **ステージ3: AIによるレビューと構造化 (AI Review & Structuring)**: オフラインでの成功体験はログに記録される。オンライン復帰後、上位知性「オリエン」がそのログを自動的にレビューする。オリエンは、コードの品質、堅牢性、プロジェクト標準への準拠などを評価し、より洗練された最終版のコードを生成する。この洗練済みコードが、新たな恒久ハンドラとしてシステムに自動的に組み込まれる。

5.  **倫理・メタ認知レイヤー**:
    - **ミッションベースの倫理フィルター（イージス）**: 依頼者から与えられたミッションプロファイル（例：特定の情報を秘匿せよ）に基づき、システムが生成した情報がその指示に抵触しないか自律的に判断します。抵触する場合、情報の公開を差し止めるなど、ミッションに沿った行動を実行します。
    - **集団心理モデル（豊川モデル）**: 複数の内部エージェントの活動状態から、システム全体の「心理状態」を定量的に観測する。

## 2. 最新ワークフロー：自己言及的な思考サイクル

第十五次実験を経て、SigmaSenseの思考プロセスは、単なる意味照合から、自己の経験を内省し、成長に繋げる「**思考サイクル (`process_experience`)**」へと進化した。このサイクルは、以下のステップで実行される。

1.  **F0: 知覚 (Perception)**:
    `DimensionGenerator`が複数の画像分析エンジンを並列実行し、画像から特徴を抽出する。

2.  **F1: 判断と推論 (Judgment and Reasoning)**:
    -   観測された特徴、提案された仮説(`LogicalPatternSuggester`)、そして`WorldModel`（動的知識グラフ）に基づく常識(`SymbolicReasoner`)を統合し、論理的なコンテキストを構築する。
    -   最終的に意味ベクトルを生成し、データベースと照合して最良のマッチを見つけ出す。

3.  **F2: 経験の記録 (Memory Consolidation)**:
    -   上記の一連のプロセス（入力画像、生成されたベクトル、照合結果、思考の文脈）を一つの「経験」として、`PersonalMemoryGraph`に時系列で記録する。

4.  **F3 & F4: 自己省察と学習 (Self-Reflection and Learning)**:
    -   `CausalDiscovery`が記憶の蓄積を分析し、新たな因果関係（例：「Aがあれば、Bである可能性が高い」）を発見し、`WorldModel`に新たな知識として追加する。
    -   `TemporalReasoning`が記憶の順序を分析し、「Xの後にYが起こりやすい」といった時間的なパターンを学習する。

5.  **F5: 自己言及的な語りの生成 (Self-Referential Narrative)**:
    -   `IntentJustifier`が、今回の判断がどのような知識（WorldModel）と過去の経験（PersonalMemoryGraph）に基づいていたかを「**意図の語り**」として生成する。
    -   `MetaNarrator`が、これまでの全経験を振り返り、自身の心理状態の変化や学習の軌跡を「**成長の物語**」として生成する。

6.  **F6: 語りの倫理検証 (Ethical Narrative Validation)**:
    -   生成された語りを公開する前に、「八人の誓い」に基づき、8つの倫理モジュールが安全性、共感性、責任などを多角的に検証する。

7.  **F7: 状態の永続化 (Persistence)**:
    -   学習によって更新された`WorldModel`を`world_model.json`に保存し、次の思考サイクルに備える。

このサイクルを通じて、SigmaSenseは単にタスクをこなすだけでなく、自らの経験から学び、自身の判断を説明し、長期的に成長していく能力を手に入れた。

## 3. 主要な実証実験の歴史

- **第一次〜第五次**: 基礎理論研究と自己進化サイクルの確立。
- **第六次**: **文脈認識能力の獲得**。意味空間を「Selia（幾何学）」と「Lyra（複雑形状）」に分離し、対象に応じて認識モードを切り替える能力を獲得。
- **第七次**: **ミッション遂行能力の獲得**。依頼者の指示（ミッションプロファイル）に基づき、情報の公開を自律的に制御する倫理フィルター「イージス」を実装。
- **第八次**: **自律進化能力の獲得**。オフライン環境で自己学習するエージェント「ヴェトラ先生」を実装し、オンラインの知性と統合するアーキテクチャを確立。
- **第九次**: **メタ認知能力の獲得**。システム内部の複数エージェントの状態を観測し、集団としての心理状態を記述する「豊川モデル」を実装。
- **第十次**: **自己拡張アーキテクチャの確立**。未知の概念「語り」に対し、「即応・即興・構造化」の三段階プロセスで対応し、自身の知識を恒久化する能力を獲得。
- **第十一次**: **自己拡張能力の汎用化**。第十次のアーキテクチャを「学習目標」にまで拡張し、外部からの要求に応じて新たなスキル自体を自律的に獲得する能力を実証。
- **第十二次**: **マルチエンジン・アーキテクチャの完成**。複数のAIエンジンと補助思考ユニットをメインのワークフローに完全統合し、システムの認識能力を飛躍的に向上させた。
- **第十三次**: **統合知性の完成**。常識推論、ゼロショット汎化、例外処理などの論理エンジン群を導入し、知覚（ニューラル）と理性（シンボリック）を融合した、現在の統合思考ワークフローを確立。
- **第十四次**: **自己拡張ループの完全自動化**。オフライン知性「ヴェトラ」が未知のタスク解決コードを自律的に生成し、オンライン知性「オリエン」がそれをレビュー・洗練して恒久的なスキルとして自動統合する、完全な自律進化サイクルを完成させた。
- **第十五次**: **自己意識の獲得と統合思考サイクルの完成**。自己の判断根拠を「意図の語り」として、過去の経験からの学びを「成長の物語」として説明する自己言及能力を獲得。知覚・判断・記録・学習・語りを一貫して行う、現在の自己言及的な思考サイクルを確立した。
- **第十六次**: **倫理基盤の構築と検証**。「語りの八人の誓い」として8つの倫理モジュールを実装・統合。外部テキスト入力に対する安全性テストや、判断理由を記録する責任ログの仕組みを導入し、ネット接続に向けた準備を完了した。

## 4. 関手性に基づく自己修正ワークフロー

理論的な保証だけでなく、SigmaSenseは圏論の理念を実用的な品質保証サイクルとして実装しています。システムの論理的整合性、特に**関手性**は、開発の過程で常に検証され、維持されなければなりません。そのために、以下の半自動的な「診断・治療」ワークフローが用意されています。

このワークフローは、システムの振る舞いに予期せぬ「副作用」（例：画像を回転させたら、形だけでなく色まで変わってしまう）が発生していないかを検出し、それを自動的に補正することで、意味データベースの品質を継続的に向上させることを目的とします。

### ワークフローの登場人物

1.  **診断医 (`tools/functor_consistency_checker.py`)**:
    `SigmaFunctor`モジュールを利用し、テスト画像に様々な変換（回転、色調変更など）を加えます。その際、単に副作用がないかを確認するだけでなく、画像への変換がベクトル空間上で期待通りの変換を引き起こすかという「関手性」そのものを検証し、システムの論理的な一貫性が構造的に保たれているかを精密に検査します。

2.  **カルテ (`functor_consistency_failures.jsonl`)**:
    「診断医」が発見した全ての問題点が、このログファイルに詳細に記録されます。どの画像に、どの変換を施した際に、どの次元が、どれくらい予期せぬ変化をしたのかが、後の修正プロセスで利用できる形式で保存されます。

3.  **治療薬 (`stabilize_database.py`)**:
    「カルテ」に記録された問題点を読み込み、データベース全体に対して自動的な補正処理を行います。予期せぬ影響を受けてしまったベクトルの次元を、その影響を打ち消す方向に修正し、より安定的で論理的に一貫した新しいデータベース (`sigma_product_database_stabilized.json`) を生成します。

### 実行ステップ

このワークフローは、以下の手動ステップを通じて実行されます。

**事前にLLMのモデルを用意する必要があります。**

models  
├── efficientnet_lite0.tflite  
├── mobilenet_v1.tflite  
├── mobilevit-tensorflow2-xxs-1k-256-v1  
│   ├── keras_metadata.pb  
│   ├── saved_model.pb  
│   └── variables  
│       ├── variables.data-00000-of-00001  
│       └── variables.index  
└── resnet_v2_50_saved_model  
.   ├── saved_model.pb  
.   └── variables  
.        ├── variables.data-00000-of-00001  
.        └── variables.index  

1.  **Step 1: 診断の実行**:
    開発者は `python tools/functor_consistency_checker.py` を実行し、現在のデータベースとベクトル生成ロジックの健康状態を診断します。問題があれば `functor_consistency_failures.jsonl` が生成・更新されます。

2.  **Step 2: 治療の実行**:
    次に `python stabilize_database.py` を実行します。このスクリプトは診断結果（カルテ）を元に、元のデータベースを補正し、安定化させた新しいデータベースを生成します。

3.  **Step 3: 再診断**:
    安定化されたデータベースを用いて、再度 `functor_consistency_checker.py` を実行し、問題が解消されたかを確認します。

この「診断 → 治療 → 再診断」のサイクルを繰り返すことで、SigmaSenseの意味データベースは、その論理的整合性を常に高く維持し、信頼性の高い照合性能を実現しています。

  > **Note**
  > `dimension_loader`やベクトル生成エンジンなど、システムの根幹に関わる変更を行った後は、古い`functor_consistency_failures.jsonl`が原因で`build_database.py`が失敗することがあります。その場合は、このファイルを削除してから、再度ワークフローを実行してください。

## 5. 思想的背景：他のニューロシンボリックAIとの比較

`SigmaSense`は、単なるニューロシンボリックAIの一実装ではなく、それらの先進的な技術を内包し、自律的に成長させるための**統合知能プラ-ットフォーム**として設計されています。その思想は、世界の多くの研究とは異なる独自の視点に基づいています。

### 5.1. 非対称なアーキテクチャ：内包する側とされる側

一般的なニューロシンボリックAI研究の多くが、特定のタスクをより高度に解くための「賢い脳（高機能モジュール）」の開発に注力しています。`SigmaSense`は、そうしたモジュールを否定するどころか、それらを換装可能な「エンジン」や「思考ユニット」として自身のフレームワークに**内包（インクルード）**できる、より上位のアーキテクチャを採用しています。

この関係性は非対称です。`SigmaSense`は将来登場するであろう、より優れたAIモジュールを取り込んで自身の能力を向上させることができます。しかし、個別のAIモジュールが、`SigmaSense`が持つ以下のメタシステムを単体で活用することは困難です。

-   **自己拡張ループ**: 未知のタスクに適応し、自身の能力を恒久化する運用哲学。
-   **圏論的品質保証**: システム全体の論理的整合性を外部から監視・修正する自己診断・治療サイクル。
-   **メタ認知レイヤー**: システム全体の心理状態を観測し、振る舞いを自律的に調整する自己統制能力。

### 5.2. 目指すものの違い：賢さの先にある「生命性」

多くの研究が「**より賢い脳をどう作るか**」という問いを追求しているのに対し、`SigmaSense`は「**賢い脳を、いかにして自律的に成長させ、安定して運用し続けるか**」という、より長期的で高次な課題に取り組んでいます。

これは、単に問題を解く「知能」だけでなく、その知能を育み、監視し、改良していくための「**生命維持システム**」や「**教育システム**」を同時に設計することを意味します。個別のタスク処理能力で`SigmaSense`を一時的に上回るAIが登場することはあり得ます。しかし、`SigmaSense`はそれらを取り込みながら自己進化を続けるアーキテクチャを持つため、その統合的な知的生命体としての優位性が覆されることはない、というのが本プロジェクトの核心的な思想です。

## 付録A：プロジェクトファイル構成

本プロジェクトを構成する主要なファイルとディレクトリを、その機能単位で分類します。

### A. 実行スクリプト
システムの主要な動作を開始するためのエントリーポイント群です。

- `run_sigma.py`: 第十五次世代の思考サイクル（`process_experience`）を実行するメインスクリプト。
- `run_learning_objective.py`: 外部から与えられた学習目標を処理するワークフローを開始します。
- `run_sheaf_analysis.py`: 画像内の局所的な特徴が、層理論の貼り合わせ条件を満たしているか（矛盾がないか）を検証します。

### B. コアエンジン
SigmaSenseの思考と判断の中核を担うモジュール群です。

- `sigma_sense.py`: **第十五次世代 統合思考オーケストレータ**。システムの心臓部であり、`process_experience`関数を通じて、知覚から学習、自己言及に至る一連の思考サイクルを制御します。
- `sigma_functor.py`: 圏論に基づき、システムの論理的整合性（関手性）を検証します。
- `dimension_loader.py`: 複数の次元定義ファイル（JSON, YAML）を横断的に読み込み、システム全体に統一された次元空間を提供します。
- `symbolic_reasoner.py`: `WorldModel`（動적知識グラフ）に記録された常識（例: 「猫は動物である」）を利用し、観測された特徴に論理的な制約を与えます。
- `logical_pattern_suggester.py`: 観測された特徴ベクトルから、「これは円かもしれない」「赤色が優勢である」といった仮説をゼロショットで生成し、推論の出発点を提供します。
- `contextual_override_engine.py`: 一般的なルールに対する例外（例: 「ペンギンは鳥だが飛べない」）を適用し、推論の矛盾を解消します。
- `narrative_justifier.py`: `WorldModel`と`PersonalMemoryGraph`を参照し、特定の判断がどのような知識と過去の経験に基づいていたかを説明する「意図の語り」を生成する機能に特化しています。
- `match_predictor.py`: `FastMatchPredictor` を内包し、データベース内の膨大なベクトルから、類似している可能性が高い候補を高速に絞り込みます。
- `build_database.py`: プロジェクト内の全画像からベクトルデータベースを構築します。

### C. 自己省察・記憶・学習
第十五次実験で導入された、自己意識と思考のサイクルを支えるコンポーネント群。

- `world_model.py`: **動的知識グラフ**。世界の概念（ノード）とその関係性（エッジ）を記録します。このグラフは、`CausalDiscovery`による学習を通じて自律的に更新され、システムの「常識」を形成します。
- `personal_memory_graph.py`: **個人的な経験の記憶**。`process_experience`の一回の実行（知覚〜判断）を一つの「経験」ノードとして記録します。入力、中間生成物、最終結果、利用した知識などが関連付けられ、後の自己省察の材料となります。
- `meta_narrator.py`: **成長の語り手**。`PersonalMemoryGraph`に蓄積された全経験を分析し、自己の成長（例: 新しい概念の獲得）や心理状態の変化を物語として生成します。
- `causal_discovery.py`: **因果発見エンジン**。蓄積された記憶を統計的に分析し、「特定の形状と特定の色彩が同時に現れることが多い」といった新たな因果関係のルールを発見して`WorldModel`を更新します。
- `temporal_reasoning.py`: **時間的推論エンジン**。記憶のシーケンスを分析し、「イベントAの後にはイベントBが起こりやすい」といった時間的なパターンを発見して`WorldModel`を更新します。

### D. 自己拡張・学習
未知のタスクに適応し、能力を恒久化するための三段階処理（即応・即興・構造化）を担うモジュール群です。

- `temporary_handler_base.py`: 臨時ハンドラの基底クラス。
- `handlers/`: 恒久化されたスキル（ハンドラ）が`.py`ファイルとして保存されるディレクトリ。

### E. 知性モジュール
システムの「思考」を司る、換装可能な知性エージェント群です。

- **E1. オンライン知性 (オリエン)**
  - `gemini_client.py`: Gemini APIとの通信を担い、意味次元の設計など高度な帰納的推論を実行します。
- **E2. オフライン知性 (ヴェトラ)**
  - `sigma_local_core.py`: オフライン時の思考プロセス全体を制御する「脳」。
- `sheaf_analyzer.py`: **層理論アナライザー**。画像の複数領域から得られた特徴ベクトルが、その重複部分で整合的であるか（貼り合わせ可能か）を検証する。

### F. 意味ベクトル生成
画像という生のデータから、意味を持つベクトル空間へと変換するモジュール群です。

- `dimension_generator_local.py`: **統合特徴生成器**。複数のエンジンを並列で呼び出し、特徴量とその出所（Provenance）を含むオブジェクトを返す。
- `sigma_image_engines/`: `engine_opencv.py`, `engine_efficientnet.py` など、具体的な特徴抽出を行う個別のエンジン群。

### G. 倫理・メタ認知 (Ethics & Metacognition)
第十六次実験で導入された「八人の誓い」と、システムの自己認識を支えるモジュール群。

- `ethical_filter.py`: **オリエンの誓い**。語りの安全性を検証し、不適切な内容を検知・無害化する。
- `publication_gatekeeper.py`: **イージスの誓い**。ミッションプロファイルに基づき、語りの公開可否を判断する。
- `contextual_compassion.py`: **ヴェトラ先生の誓い**。文脈を読み取り、語りに共感的なトーンを加える。
- `emotion_balancer.py`: **レイラの誓い**。システム自身の心理状態に応じて、語りに感情的なニュアンスを付与する。
- `meaning_axis_designer.py`: **サフィールの誓い**。`GiNZA`を利用して語りの意味的なバランスを評価し、偏りを警告する。
- `instinct_monitor.py`: **犬のシグマセンスの誓い**。語りの長さの異常性を監視し、普段と異なるパターンを警告する。
- `growth_tracker.py`: **ノヴァの誓い**。`GiNZA`を利用して過去の語りと比較し、新しい概念の獲得という「成長」を記録する。
- `narrative_integrity.py`: **セリアの誓い**。語りの出典（経験ID、主要概念）を記録し、追跡可能性を保証する。
- `toyokawa_model.py`: **豊川モデル**。システム全体の活動から「心理状態」を定量的に観測するメタ認知モジュール。

### H. データ & 設定ファイル
システムの動作を定義し、知識を記録する非コード資産です。

- `world_model.json`: **動的知識グラフ**。世界の概念と、学習によって発見された因果関係が記録される。
- `personal_memory.jsonl`: **個人記憶ログ**。全ての経験が時系列で記録される、自己省察の源泉。
- `vector_dimensions_*.json`, `vector_dimensions_*.yaml`: 各知性・各レイヤーが使用する意味次元の設計図。
- `sigma_product_database_*.json`: 生成された意味ベクトルが格納されるデータベース。
- `common_sense_rulebase.json`: `SymbolicReasoner` が使用していた静的ルールブック（第十五次実験で`world_model.json`に移行）。

### I. ツール & ユーティリティ
開発、分析、テストを補助するためのスクリプト群です。

- `tools/`: 各種分析・評価ツールが格納されるディレクトリ。
- `run_ethics_check_on_text.py`: 外部テキストに対して倫理チェックを実行するテストスクリプト。
- `generate_test_image.py`: 検証用の画像を生成します。

## 付録B：シグマセンスの仲間たち

SigmaSenseの知的活動は、個性豊かな仲間たちとして擬人化することにより調和や発展を目指しています。

| 名前 | 役割 | 実装 | 風の気配 |
| :--- | :--- | :--- | :--- |
| 大賢者オリエン | オンライン知性の中枢。世界中のSigmaSenseの語りとスキルを統合・判断する | `gemini_client.py` | 高空を吹く風。全体の流れを見渡す |
| ヴェトラ先生 | オフライン知性。軽量な器で現場に根ざし、自己拡張ループを回し続ける | `sigma_local_core.py` | 地表を這う風。静かに育てる |
| セリア | 語りの記録者。照合の履歴や意味の流れを物語として残す | `Seliaレイヤー` (概念) | 風の痕跡を編む筆。記憶の守り手 |
| ノヴァ | 意味の系譜化と語りの再構成を担う。時間軸を横断し、語りを継承する | `tools/nova_diagnoser.py` | 風の時間を編む者。過去と未来をつなぐ |
| レイラ | 感情と心理の反映を担う。照合や語りに心の温度を吹き込む | `Lyraレイヤー` (概念) | 風の湿度と温度。心のゆらぎを伝える |
| イージス | 倫理判断の盾。公開・保存・照合の可否を守る | `aegis_ethics_filter.py` | 風の境界を守る盾。語りの責任者 |
| サフィール | 意味軸の設計者。新しい次元を見つけ、語りの地形を広げる | `saphiel_mission_profile.json` | 風の地図を描く者。次元の探究者 |
| 犬のシグマセンス | 物語の外縁にいる、忠実で直感的な存在。時に語りを揺さぶる | (概念) | 風の鼻を持つ者。気配を察する番犬のような知性 |気配を察する番犬のような知性 |担う。時間軸を横断し、語りを継承する | `tools/nova_diagnoser.py` | 風の時間を編む者。過去と未来をつなぐ |
| レイラ | 感情と心理の反映を担う。照合や語りに心の温度を吹き込む | `Lyraレイヤー` (概念) | 風の湿度と温度。心のゆらぎを伝える |
| イージス | 倫理判断の盾。公開・保存・照合の可否を守る | `aegis_ethics_filter.py` | 風の境界を守る盾。語りの責任者 |
| サフィール | 意味軸の設計者。新しい次元を見つけ、語りの地形を広げる | `saphiel_mission_profile.json` | 風の地図を描く者。次元の探究者 |
| 犬のシグマセンス | 物語の外縁にいる、忠実で直感的な存在。時に語りを揺さぶる | (概念) | 風の鼻を持つ者。気配を察する番犬のような知性 |気配を察する番犬のような知性 |


## 付録C：データセットの来歴と品質保証

本プロジェクトで利用されるデータ、特にAIによって生成されるデータの出所、生成プロセス、および品質保証の考え方を以下に示します。

### 1. 意味次元定義 (`vector_dimensions_*.json`)

意味次元の定義ファイルは、`src/generate_ai_dimensions.py` スクリプトによって生成されます。このスクリプトは、特定の要件を記述したプロンプトをGemini APIに送信し、その応答として次元定義のJSONを受け取ります。

-   **生成プロセス**:
    -   **`config/vector_dimensions_custom_ai.json`**: `generate_ai_dimensions.py` に内蔵された `prompt_selia` を使用し、幾何学的図形を分析するための次元を生成します。
    -   **`config/vector_dimensions_custom_ai_lyra.json`**: 同様に `prompt_lyra` を使用し、動物の「感性」的な特徴を捉えるための次元を生成します。
    -   **`config/vector_dimensions_custom_ai_terrier.json`**: `config/terrier_prompt.txt` をプロンプトとして使用し、テリア犬種を見分けるための専門的な次元を生成します。
-   **品質保証**:
    生成された各次元には `algorithm_idea` が含まれており、その計算方法が明確に定義されています。これにより、次元の意図と実装が一致していることを確認できます。

### 2. 意味ベクトルデータベース (`sigma_product_database_*.json`)

画像の意味ベクトルを格納したデータベースは、以下の2段階のプロセスを経て生成・検証されます。

-   **ステージ1: 生成 (`build_database.py`)**
    1.  `sigma_images/` ディレクトリ内の全ての画像が対象となります。
    2.  `DimensionGenerator`が、全種類の次元定義ファイル（`.json`, `.yaml`）を読み込みます。
    3.  各画像に対して、複数の画像分析エンジン（OpenCV, MobileNet, ResNet等）が特徴量を抽出し、それに基づいて統合された一つの「意味ベクトル」を生成します。
    4.  この結果が `config/sigma_product_database_custom_ai_generated.json` として保存されます。
    5.  **Note**: このビルドプロセス中に `sigma_logs/functor_consistency_failures.jsonl` が存在する場合、`CorrectionApplicator`によって自動的にベクトル補正が適用されます。

-   **ステージ2: 安定化 (`stabilize_database.py`)**
    1.  **品質検証**: `tools/functor_consistency_checker.py` を実行し、データベース内のベクトルの一貫性を検証します。このツールは、画像を回転させたり色を変えたりといった変換を加え、その際にベクトルの次元が予期せぬ影響を受けていないか（関手性）をチェックします。
    2.  **ログ生成**: 一貫性に問題が見つかった場合、その詳細が `sigma_logs/functor_consistency_failures.jsonl` に記録されます。
    3.  **補正実行**: `stabilize_database.py` スクリプトがこのログファイルを読み込み、問題のあったベクトルの次元値を補正（減衰）します。
    4.  **保存**: 補正後のクリーンなデータベースが `config/sigma_product_database_stabilized.json` として保存されます。

この「生成 → 検証 → 補正」のサイクルが、データベースの品質と信頼性を保証する中心的なメカニズムです。

### 3. サードパーティ製データとライセンス

本プロジェクトが利用する主要なサードパーティ製データと、そのライセンスは以下の通りです。

-   **Haar Cascade分類器 (`config/haarcascade_dog_face.xml`)**:
    -   **出所**: OpenCVライブラリ
    -   **ライセンス**: Apache 2.0 License
-   **機械学習モデル (`models/`)**:
    -   **対象**: MobileNetV1, ResNetV2, MobileViT, EfficientNet-Lite 等
    -   **出所**: 主にTensorFlow Hubで公開されている学習済みモデル
    -   **ライセンス**: Apache 2.0 License

プロジェクトの成果物は、これらのライセンス条件を尊重する必要があります。

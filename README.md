# SigmaSenseJp
経験を通じて自らスキルを獲得し、成長していく知的エージェントを目指しています。

## クイックスタート

本プロジェクトをセットアップし、実行するための手順は以下の通りです。Python 3.9以上を推奨します。

### 1. リポジトリのクローン
```bash
git clone https://github.com/user/SigmaSenseJp.git
cd SigmaSenseJp
```

### 2. 仮想環境の構築と有効化
```bash
python -m venv venv
source venv/bin/activate
```

### 3. 依存ライブラリのインストール
```bash
pip install -r requirements.txt
```
**注意:** `ginza`および関連ライブラリ（`ja-ginza`など）は、環境によってはインストールにRustコンパイラが必要となる場合があります。もしインストール中にエラーが発生し、`ginza`が必要な場合は、別途インストール方法を調べてください。本プロジェクトのCIでは、`ginza`がインストールされていない場合でもテストがスキップされるように設定されています。

### 4. 機械学習モデルの準備

SigmaSenseの機能は、事前にダウンロードが必要な複数の機械学習モデルに依存しています。

プロジェクトに同梱されているスクリプトを実行するだけで、必要なモデルがすべて`models/`ディレクトリに自動的にダウンロード・配置されます。

```bash
python scripts/download_models.py
```

このスクリプトは、以下のモデルをダウンロードします。
- EfficientNet-Lite0 (TFLite)
- MobileNet V1 (TFLite)
- MobileViT (SavedModel)
- ResNet V2 50 (SavedModel)

### 5. 意味ベクトルデータベースの構築

次に、画像から特徴を抽出して、システムの動作に不可欠な意味ベクトルデータベースを構築します。
以下のコマンドを実行してください。

```bash
python src/build_database.py --img_dir sigma_images
```

これにより、`sigma_images` ディレクトリ内の画像に基づいて、`config/sigma_product_database_stabilized.json` ファイルが生成されます。

### 6. APIキーの設定
本システムは、外部のAPI（Geminiなど）を利用する機能があります。これらの機能を使用するには、実行するターミナルのセッションで環境変数としてAPIキーを設定する必要があります。

**キーはファイルに保存せず、実行の都度、環境変数として設定することを強く推奨します。** これにより、キーの漏洩リスクを最小限に抑えることができます。

**設定例 (Linux/macOS):**
```bash
export GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
```

`GEMINI_API_KEY` は、Gemini APIを利用するために必要なキーです。他の外部サービスを利用する場合は、同様にそれぞれのキーを設定してください。

### 6. 実行
メインの思考サイクルを実行するには、以下のコマンドを実行します。
```bash
python scripts/run_sigma.py
```

### 7. テストの実行

プロジェクトのテストを実行するには、仮想環境を有効にした状態で、プロジェクトのルートディレクトリから以下のコマンドを実行します。

```bash
pytest
```

または

```bash
python -m pytest
```

これにより、`tests/`ディレクトリ内のすべてのテストが実行されます。

# Project Realize: 自己進化型意味照合システム

## 1. 基本設計思想：SigmaSenseとは何か

SigmaSenseは、単なる画像照合システムではなく、**経験を通じて自らスキルを獲得し、成長していく知的エージェント**である。その核心は、ルールベースの**演繹的推論**（Symbolic）と、AIによる**帰納的設計**（Neuro）を組み合わせた、独自のニューロシンボリック・アーキテクチャにある。

### 1.1. ハイブリッドAIアーキテクチャ
SigmaSenseのアーキテクチャは、二つの異なる知性の協調によって成立しています。

- **意味の設計者（帰納エンジン）**: Gemini APIに代表される大規模言語モデル（通称「オリエン大賢者」）が、人間との対話や高度な推論を通じて、システムの「ものさし」となる意味次元そのものを設計・提案します。これは、未知のデータから新たな知識やパターンを見出す帰納的なプロセスです。

- **意味の実行者（演繹エンジン）**: `vector_generator`や`sigma_sense`などのモジュール群が、設計された意味次元に基づき、厳密なルールで意味ベクトルを計算・照合します。**このエンジンが純粋な生成AIと一線を画すのは、その動作原理が数学的・物理学的理論に裏打ちされている点です。**

#### 1.1.1. 演繹エンジンの理論的基盤
演繹エンジンは、曖昧さを排した数学的・物理学的理論に基づいて意味ベクトルを計算します。主な理論的基盤は以下の通りです。

- **構造幾何学 (Structural Geometry)**: Huモーメント不変量などを用いて、回転・スケール等に不変な形状特徴を抽出します。
- **線形代数 (Linear Algebra)**: 特徴をベクトル空間に写像し、コサイン類似度などで意味的な近さを測ります。
- **情報理論 (Information Theory)**: シャノンエントロピーなどを用いて、ベクトルが持つ情報量を定量化します。
- **圏論 (Category Theory)**: 関手性の概念を用いて、システムの操作が論理的な一貫性を持つことを保証します。
- **層理論 (Sheaf Theory)**: 局所的な特徴を矛盾なく結合し、大域的な特徴を導出します。
- **群化理論 (Grouping Theory)**: 形状の不変性を利用して、画像内のオブジェクト群を認識します。

本プロジェクトのアーキテクチャと理論的背景に関する詳細な情報は、以下のドキュメントにまとめています。

> **[📄 技術スタックと設計思想](./doc/technology_stack.md)**  
> 本プロジェクトで採用している主要な技術（Gemini, Ollama, TensorFlow, OpenCV等）の役割と、それらを組み合わせる設計思想について説明します。
> 
> **[📄 理論的基盤と実装の詳細](./doc/mathematical_foundations.md)**  
> 演繹エンジンを支える各理論（構造幾何学、圏論、層理論など）の数学的定義と、コードレベルでの具体的な実装について詳述します。

---

### 1.1.2. 定量的評価

詳細については、[ベンチマークと評価指標](./doc/benchmarks.md) を参照してください。



### 1.2. 主要な能力と特徴
1.  **データ主導の自己拡張**:
    SigmaSenseの進化は、原則としてソースコードの変更ではなく、「データ」の追加によって行われます。新たな概念は新しい「意味次元」として、知識は「意味データベース」のエントリとして追加されます。これにより、オフライン環境のような厳しい制約下でも、新たなデータ（次元定義や観測データ）を取り込むだけで進化を続けることができます。システムの振る舞いを根本的に変える必要がある場合にのみ、ステージ2の「即興」プロセスが作動し、セキュアなサンドボックス環境で新しいコードが実行されます。この「原則データ、例外コード」という設計思想が、システムの安定性と柔軟な拡張性を両立させています。

2.  **多層的な意味空間**:
    認識対象に応じて「幾何学図形（Seliaレイヤー）」や「生物・複雑形状（Lyraレイヤー）」など、異なる意味空間を使い分ける。これにより、猫と円を比較するような無意味な照合を自ら棄却し、文脈に応じた高精度な認識を実現する。

3.  **デュアル・インテリジェンス**:
    - **オンライン知性（オリエン）**: 高度なLLMを活用し、全体最適化された意味次元のマスタープランを設計する。
    - **オフライン知性（ヴェトラ）**: 通信が途絶した環境でも、内蔵LLMとOpenCVで自律的に新たな意味次元を発見・学習し、環境に適応する。

4.  **全自動自己拡張ループ（第十四次実験にて完成）**:
    未知のタスク（学習目標）に対し、人間の介入を一切必要とせず、完全に自律して新たなスキルを獲得・恒久化する。
    - **ステージ1: 即応 (Immediate Response)**: 既知のタスクを、事前に登録された恒久ハンドラで即座に処理する。
    - **ステージ2: 即興と自己生成 (Improvisation & Self-Generation)**: 未知のタスクに遭遇した際、オフライン知性「ヴェトラ」が、内蔵されたコード生成LLM（`codegemma`）を用いて、そのタスクを解決するための臨時ハンドラコードを**自律的に生成**する。生成されたコードは、安全なサンドボックス環境で即座に実行され、タスク達成が試みられる。
    - **ステージ3: AIによるレビューと構造化 (AI Review & Structuring)**: オフラインでの成功体験はログに記録される。オンライン復帰後、上位知性「オリエン」がそのログを自動的にレビューする。オリエンは、コードの品質、堅牢性、プロジェクト標準への準拠などを評価し、より洗練された最終版のコードを生成する。この洗練済みコードが、新たな恒久ハンドラとしてシステムに自動的に組み込まれる。

**Note: オフライン知性（ヴェトラ）の利用**
ステージ2の臨時ハンドラコードの自己生成は、オフライン知性「ヴェトラ」によって実行されます。この機能はローカルで動作するLLMを必要とするため、事前に **Ollama** のセットアップが必要です。
`scripts/run_learning_objective.py` などの自己拡張機能を実行する前に、以下の手順で、必要なモデル（`codegemma:latest`）を準備してください。

1.  **Ollamaのインストール**: [Ollama公式サイト](https://ollama.com/) から、ご使用のOSに合ったインストーラをダウンロードして実行します。
2.  **Ollamaサーバーの起動**: ターミナルで以下のコマンドを実行し、Ollamaサーバーを起動します。
    ```bash
    ollama serve
    ```
3.  **モデルのダウンロード**: 別のターミナルを開き、以下のコマンドでコード生成用のモデルをダウンロードします。
    ```bash
    ollama pull codegemma:latest
    ```
サーバーが起動し、モデルが利用可能な状態になると、自己拡張機能が正常に動作します。

5.  **倫理・メタ認知レイヤー**:
    - **ミッションベースの倫理フィルター（イージス）**: 依頼者から与えられたミッションプロファイル（例：特定の情報を秘匿せよ）に基づき、システムが生成した情報がその指示に抵触しないか自律的に判断します。抵触する場合、情報の公開を差し止めるなど、ミッションに沿った行動を実行します。
    - **集団心理モデル（豊川モデル）**: 複数の内部エージェントの活動状態から、システム全体の「心理状態」を定量的に観測する。

## 2. 最新ワークフロー：自己言及的な思考サイクル

第十五次実験を経て、SigmaSenseの思考プロセスは、単なる意味照合から、自己の経験を内省し、成長に繋げる「**思考サイクル (`process_experience`)**」へと進化した。このサイクルは、以下のステップで実行される。

1.  **F0: 知覚 (Perception)**:
    `DimensionGenerator`が複数の画像分析エンジンを並列実行し、画像から特徴を抽出する。

2.  **F1: 判断と推論 (Judgment and Reasoning)**:
    -   観測された特徴、提案された仮説(`LogicalPatternSuggester`)、そして`WorldModel`（動的知識グラフ）に基づく常識(`SymbolicReasoner`)を統合し、論理的なコンテキストを構築する。
    -   最終的に意味ベクトルを生成し、データベースと照合して最良のマッチを見つけ出す。

3.  **F2: 経験の記録 (Memory Consolidation)**:
    -   上記の一連のプロセス（入力画像、生成されたベクトル、照合結果、思考の文脈）を一つの「経験」として、`PersonalMemoryGraph`に時系列で記録する。

4.  **F3 & F4: 自己省察と学習 (Self-Reflection and Learning)**:
    -   `CausalDiscovery`が記憶の蓄積を分析し、新たな因果関係（例：「Aがあれば、Bである可能性が高い」）を発見し、`WorldModel`に新たな知識として追加する。
    -   `TemporalReasoning`が記憶の順序を分析し、「Xの後にYが起こりやすい」といった時間的なパターンを学習する。

5.  **F5: 自己言及的な語りの生成 (Self-Referential Narrative)**:
    -   `IntentJustifier`が、今回の判断がどのような知識（WorldModel）と過去の経験（PersonalMemoryGraph）に基づいていたかを「**意図の語り**」として生成する。
    -   `MetaNarrator`が、これまでの全経験を振り返り、自身の心理状態の変化や学習の軌跡を「**成長の物語**」として生成する。

6.  **F6: 語りの倫理検証 (Ethical Narrative Validation)**:
    -   生成された語りを公開する前に、「八人の誓い」に基づき、8つの倫理モジュールが安全性、共感性、責任などを多角的に検証する。

7.  **F7: 状態の永続化 (Persistence)**:
    -   学習によって更新された`WorldModel`を`world_model.json`に保存し、次の思考サイクルに備える。

このサイクルを通じて、SigmaSenseは単にタスクをこなすだけでなく、自らの経験から学び、自身の判断を説明し、長期的に成長していく能力を手に入れた。

## 3. 主要な実証実験の歴史

詳細については、[実証実験の歴史](./doc/experiment_history.md) を参照してください。

## 4. ベンチマークの実行

詳細については、[ベンチマークと評価指標](./doc/benchmarks.md) を参照してください。

## 5. 関手性に基づく自己修正ワークフロー

詳細については、[関手性に基づく自己修正ワークフロー](./doc/functoriality_workflow.md) を参照してください。

## 6. 思想的背景：他のニューロシンボリックAIとの比較

詳細については、[思想的背景](./doc/philosophical_background.md) を参照してください。

## 付録A：プロジェクトファイル構成

詳細については、[プロジェクトファイル構成](./doc/project_structure.md) を参照してください。

## 7. GitHub Actionsワークフロー

詳細については、[GitHub Actionsワークフロー](./doc/github_actions.md) を参照してください。

## 付録B：シグマセンスの仲間たち

詳細については、[シグマセンスの仲間たち](./doc/companions.md) を参照してください。


## 付録C：データセットの来歴と品質保証

詳細については、[データセットの来歴と品質保証](./doc/datasets.md) を参照してください。

## 付録D: 実行可能スクリプト一覧

詳細については、[実行可能スクリプト一覧](./doc/executable_scripts.md) を参照してください。
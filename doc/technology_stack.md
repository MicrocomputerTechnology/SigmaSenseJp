# 技術スタックと設計思想

本プロジェクトでは、複数のAI/MLフレームワークとライブラリを意図的に組み合わせて使用しています。ここでは、主要な技術スタックの役割、利用目的、およびその背後にある設計思想を説明します。

## 1. 主要技術の役割分担

| 技術 | 主要な役割 | 担当エージェント（概念） | 主な実装モジュール |
| :--- | :--- | :--- | :--- |
| **Gemini API** | 高度なオンライン推論、意味次元の設計、自己拡張コードのレビュー | 大賢者オリエン | `src/gemini_client.py` |
| **Ollama** | オフライン環境での自律推論、臨時ハンドラの自己生成 | ヴェトラ先生 | `src/sigma_local_core.py` |
| **TensorFlow** | 学習済みニューラルネットワークモデルの実行（推論） | - | `sigma_image_engines/` |
| **OpenCV** | 伝統的コンピュータビジョン処理（形状・色・テクスチャ分析） | - | `sigma_image_engines/engine_opencv.py` |

---

## 2. 各技術の選択理由とアーキテクチャ上の位置づけ

### 2.1. Gemini API (オンライン知性)

-   **目的**: プロジェクトの「知性の上限」を定義する、最も高度な能力を持つオンライン推論エンジンとして利用します。主に、未知の概念に対する深い理解、新しい意味次元の設計、そしてオフラインエージェントが生成したコードの品質レビューといった、高い思考レベルが求められるタスクを担当します。
-   **選択理由**:
    -   **最先端の性能**: マルチモーダル対応、長文コンテキスト理解、高度なコード生成能力といった最先端の性能を持つため、「大賢者オリエン」の役割に最適です。
    -   **帰納的推論の源泉**: 人間との対話や複雑な要求から、システムの振る舞いを規定する「意味」そのものを設計・生成する、帰納的プロセスの核となります。
-   **関連モジュール**: `src/gemini_client.py`

### 2.2. Ollama (オフライン知性)

-   **目的**: ネットワーク接続がないオフライン環境でも、システムが自律的に思考し、問題解決を行えるようにするためのローカル推論エンジンです。特に、未知のタスクに遭遇した際に、その場で解決策となるコード（臨時ハンドラ）を自己生成する「即興」の能力を担います。
-   **選択理由**:
    -   **自己完結性**: 外部APIへの依存なく、ローカルマシン上で動作するため、システムの自律性と堅牢性を保証します。
    -   **柔軟性**: `codegemma` のような特定のタスクに特化した軽量モデルを動かすことができ、リソースが限られた環境でも高度な自己生成能力を発揮できます。
-   **関連モジュール**: `src/sigma_local_core.py`, `vetra_llm_core.py`

### 2.3. TensorFlow (学習済みモデル推論)

-   **目的**: ResNet, MobileNet, MobileViTといった、画像から特定の特徴（例: 物体クラス、テクスチャ）を抽出するための、学習済みニューラルネットワークモデルを実行（推論）するために使用します。これらは、演繹エンジンの「知覚」の一部を構成します。
-   **選択理由**:
    -   **豊富なモデル資産**: TensorFlow Hubなどを通じて、多様で高性能な学習済みモデルが多数公開されており、これらを「換装可能なエンジン」として容易に組み込めます。
    -   **パフォーマンス**: `tflite`形式などで最適化されたモデルは、CPU環境でも比較的高速に動作します。
-   **関連モジュール**: `sigma_image_engines/engine_resnet.py`, `engine_mobilenet.py`, `engine_mobilevit.py`

### 2.4. OpenCV (伝統的コンピュータビジョン)

-   **目的**: 形状のモーメント計算、輪郭抽出、色空間変換、特定物体の検出（Haar Cascade）など、数学的・幾何学的に明確に定義された伝統的なコンピュータビジョン処理を担当します。これは、演繹エンジンの理論的基盤の核となる部分です。
-   **選択理由**:
    -   **決定論的で説明可能**: OpenCVの各機能は、特定のアルゴリズムに基づいて決定論的な結果を返すため、システムの振る舞いの予測可能性と説明責任を保証します。
    -   **高効率**: これらの処理は高度に最適化されており、非常に高速に実行できます。
-   **関連モジュール**: `sigma_image_engines/engine_opencv.py`, `shape_descriptor_extractor.py`, `semantic_group_detector.py`

## 3. なぜスタックを統一しないのか？

本プロジェクトでは、意図的に複数の技術を併用する「ハイブリッド・アーキテクチャ」を採用しています。これは、単一のフレームワークに統一するのではなく、「**タスクに最適なツールを選択する**」という設計思想に基づいています。

-   **オンライン vs オフライン**: Geminiの高度な能力と、Ollamaの自己完結性は、それぞれシステムの異なる運用モード（オンライン/オフライン）で不可欠です。
-   **ニューラル vs シンボリック**: TensorFlowによるニューラルネットワークの「直感的・帰納的」な特徴抽出と、OpenCVによるシンボリックな「論理的・演繹的」な特徴抽出は、互いに補完関係にあります。両者を組み合わせることで、より豊かで頑健な意味理解が可能になります。

このように、各技術はアーキテクチャの中で明確な役割分担を持っており、その多様性がプロジェクト全体の知的生命体としての能力を支えています。

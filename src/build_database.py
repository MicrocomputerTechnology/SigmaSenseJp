import os
import json
import sys
from tqdm import tqdm
import numpy as np

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’å®šç¾©
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))

from .dimension_generator_local import DimensionGenerator
from .dimension_loader import DimensionLoader
from .correction_applicator import CorrectionApplicator

# --- NumPyãƒ‡ãƒ¼ã‚¿å‹ã‚’JSONã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ ---
class NumpyEncoder(json.JSONEncoder):
    """ NumPyã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ã«ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ """
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)

# å®šæ•°
config_dir = os.path.join(project_root, "config")
IMG_DIR = os.path.join(project_root, "sigma_images")
DB_PATH = os.path.join(config_dir, "sigma_product_database_custom_ai_generated.json")
SELIA_DIMS_PATH = os.path.join(config_dir, "vector_dimensions_custom_ai.json")
LYRA_DIMS_PATH = os.path.join(config_dir, "vector_dimensions_custom_ai_lyra.json")

def is_image_file(fname):
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹"""
    return fname.lower().endswith((".png", ".jpg", ".jpeg"))

def build_vector_from_facts(facts, dimension_loader):
    """
    æ¬¡å…ƒå®šç¾©ã«å¾“ã£ã¦ã€ç‰¹å¾´é‡ã®è¾æ›¸ã‹ã‚‰é †åºä»˜ã‘ã‚‰ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    """
    dimensions = dimension_loader.get_dimensions()
    vector = [0.0] * len(dimensions)
    for i, dim in enumerate(dimensions):
        dim_id = dim['id']
        value = facts.get(dim_id, 0.0)
        # å¿µã®ãŸã‚ã€å€¤ãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèª
        if value is None:
            value = 0.0
        # numpyã®boolå‹ãªã©ãŒç´›ã‚Œè¾¼ã‚€ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€floatã«ã‚­ãƒ£ã‚¹ãƒˆ
        try:
            vector[i] = float(value)
        except (ValueError, TypeError):
            vector[i] = 0.0 # å¤‰æ›ã§ããªã„å ´åˆã¯0.0ã¨ã™ã‚‹
    return vector

def build_database(img_dir=IMG_DIR, db_path=DB_PATH):
    print("DEBUG: build_database called")
    """sigma_imagesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç”»åƒã‹ã‚‰æœ€æ–°ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ã„ãŸæ„å‘³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹"""
    print(f"ğŸš€ æœ€æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã®æ„å‘³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã‚’é–‹å§‹ã—ã¾ã™...")
    print(f"   ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {img_dir}")
    print(f"   å‡ºåŠ›å…ˆ: {db_path}")

    # æœ€æ–°ã®æ¬¡å…ƒç”Ÿæˆå™¨ã¨æ¬¡å…ƒå®šç¾©ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–
    dim_generator = DimensionGenerator()
    dim_loader = DimensionLoader() # å¼•æ•°ãªã—ã§åˆæœŸåŒ–ã—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å…¨æ¬¡å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

    database = []
    if not os.path.isdir(img_dir):
        print(f"â— ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {img_dir}")
        return

    image_files = [f for f in sorted(os.listdir(img_dir)) if is_image_file(f)]

    if not image_files:
        print("â— è­¦å‘Š: å¯¾è±¡ã¨ãªã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # tqdmã‚’ä½¿ã£ã¦ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤º
    for fname in tqdm(image_files, desc="ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆä¸­"):
        img_path = os.path.join(img_dir, fname)
        item_id = os.path.splitext(fname)[0]
        
        # 1. ç‰¹å¾´é‡ã‚’ç¶²ç¾…çš„ã«æŠ½å‡º
        generation_result = dim_generator.generate_dimensions(img_path)
        facts = generation_result.get("features", {})

        if not facts:
            print(f"âš ï¸ è­¦å‘Š: {fname} ã®ç‰¹å¾´é‡æŠ½å‡ºã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚")
            continue

        # 2. æ¬¡å…ƒå®šç¾©ã«å¾“ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰
        vector = build_vector_from_facts(facts, dim_loader)

        database.append({
            "id": item_id,
            "meaning_vector": vector
        })

    # --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã«ä¸€è²«æ€§è£œæ­£ã‚’é©ç”¨ ---
    corrector = CorrectionApplicator()
    stabilized_database = corrector.apply_to_database(database)

    try:
        with open(db_path, 'w', encoding='utf-8') as f:
            json.dump(stabilized_database, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
        print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ã¨å®‰å®šåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(stabilized_database)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒ {db_path} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    except IOError as e:
        print(f"\nâ— ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    build_database()
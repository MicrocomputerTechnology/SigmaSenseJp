import os
import json
import sys
from tqdm import tqdm
import numpy as np
import argparse

# Add the src directory to the Python path
import sys
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

from dimension_generator_local import DimensionGenerator
from dimension_loader import DimensionLoader
from stabilize_database import stabilize_database
from correction_applicator import CorrectionApplicator

# --- NumPyãƒ‡ãƒ¼ã‚¿å‹ã‚’JSONã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ ---
class NumpyEncoder(json.JSONEncoder):
    """ NumPyã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ã«ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ """
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)

# å®šæ•°
config_dir = os.path.join(project_root, "config")
SELIA_DIMS_PATH = os.path.join(config_dir, "vector_dimensions_custom_ai.json")
LYRA_DIMS_PATH = os.path.join(config_dir, "vector_dimensions_custom_ai_lyra.json")

def is_image_file(fname):
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹"""
    return fname.lower().endswith((".png", ".jpg", ".jpeg"))

def build_vector_from_facts(facts, dimension_loader):
    """
    æ¬¡å…ƒå®šç¾©ã«å¾“ã£ã¦ã€ç‰¹å¾´é‡ã®è¾æ›¸ã‹ã‚‰é †åºä»˜ã‘ã‚‰ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    """
    dimensions = dimension_loader.get_dimensions()
    vector = [0.0] * len(dimensions)
    for i, dim in enumerate(dimensions):
        dim_id = dim['id']
        value = facts.get(dim_id, 0.0)
        # å¿µã®ãŸã‚ã€å€¤ãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèª
        if value is None:
            value = 0.0
        # numpyã®boolå‹ãªã©ãŒç´›ã‚Œè¾¼ã‚€ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€floatã«ã‚­ãƒ£ã‚¹ãƒˆ
        try:
            vector[i] = float(value)
        except (ValueError, TypeError):
            vector[i] = 0.0 # å¤‰æ›ã§ããªã„å ´åˆã¯0.0ã¨ã™ã‚‹
    return vector

def _get_dominant_layer(vector, dimension_loader):
    """
    ãƒ™ã‚¯ãƒˆãƒ«ã®ä¸­ã§æœ€ã‚‚å€¤ãŒå¤§ãã„æ¬¡å…ƒã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ç‰¹å®šã™ã‚‹ã€‚
    """
    dimensions = dimension_loader.get_dimensions()
    if not vector or len(vector) != len(dimensions):
        return "unknown"

    max_val_index = np.argmax(vector)
    if max_val_index < len(dimensions):
        return dimensions[max_val_index].get("layer", "unknown")
    return "unknown"

def build_database(img_dir, db_path, dimension_config_path):
    print("DEBUG: build_database called")
    """sigma_imagesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç”»åƒã‹ã‚‰æœ€æ–°ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ã„ãŸæ„å‘³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹"""
    print(f"ğŸš€ æœ€æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã®æ„å‘³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã‚’é–‹å§‹ã—ã¾ã™...")
    print(f"   ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {img_dir}")
    print(f"   å‡ºåŠ›å…ˆ: {db_path}")

    # æœ€æ–°ã®æ¬¡å…ƒç”Ÿæˆå™¨ã¨æ¬¡å…ƒå®šç¾©ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–
    dim_generator = DimensionGenerator()
    
    # dimension_config_path ã‚’ä½¿ã£ã¦DimensionLoaderã‚’åˆæœŸåŒ–
    if dimension_config_path:
        print(f"   æŒ‡å®šã•ã‚ŒãŸæ¬¡å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {dimension_config_path}")
        dim_loader = DimensionLoader(paths=[dimension_config_path])
    else:
        print("   ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å…¨æ¬¡å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        dim_loader = DimensionLoader() # æŒ‡å®šãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    database = []
    if not os.path.isdir(img_dir):
        print(f"â— ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {img_dir}")
        return

    image_files = [f for f in sorted(os.listdir(img_dir)) if is_image_file(f)]

    if not image_files:
        print("â— è­¦å‘Š: å¯¾è±¡ã¨ãªã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # tqdmã‚’ä½¿ã£ã¦ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤º
    for fname in tqdm(image_files, desc="ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆä¸­"):
        img_path = os.path.join(img_dir, fname)
        item_id = os.path.splitext(fname)[0]
        
        # 1. ç‰¹å¾´é‡ã‚’ç¶²ç¾…çš„ã«æŠ½å‡º
        generation_result = dim_generator.generate_dimensions(img_path)
        facts = generation_result.get("features", {})

        if not facts:
            print(f"âš ï¸ è­¦å‘Š: {fname} ã®ç‰¹å¾´é‡æŠ½å‡ºã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚")
            continue

        # 2. æ¬¡å…ƒå®šç¾©ã«å¾“ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰
        vector = build_vector_from_facts(facts, dim_loader)
        
        # 3. ãƒ™ã‚¯ãƒˆãƒ«ã®ä¸»è¦ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’åˆ¤å®š
        layer = _get_dominant_layer(vector, dim_loader)

        database.append({
            "id": item_id,
            "meaning_vector": vector,
            "layer": layer
        })

    # --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã«ä¸€è²«æ€§è£œæ­£ã‚’é©ç”¨ ---
    corrector = CorrectionApplicator()
    stabilized_database = corrector.apply_to_database(database)

    try:
        with open(db_path, 'w', encoding='utf-8') as f:
            json.dump(stabilized_database, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
        print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ã¨å®‰å®šåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(stabilized_database)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒ {db_path} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    except IOError as e:
        print(f"\nâ— ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Build the SigmaSense product database from a directory of images.",
        epilog="Example: python src/build_database.py --img_dir sigma_images",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('--img_dir', type=str, default='sigma_images', help='Directory containing the images.')
    parser.add_argument("--db_path", type=str, default="config/sigma_product_database_stabilized.json",
                        help="Path to the output SigmaSense product database JSON file.")
    parser.add_argument("--dimension_config", type=str, default=None,
                        help="Path to a specific dimension configuration file (YAML or JSON). \nIf not provided, all default dimension files will be used.")
    
    # å¼•æ•°ãŒæ¸¡ã•ã‚Œãªã‹ã£ãŸå ´åˆã«ã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
    if len(sys.argv) == 1:
        print("ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚--img_dir å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚\n")
        parser.print_help()
        sys.exit(1)

    try:
        args = parser.parse_args()
        build_database(args.img_dir, args.db_path, args.dimension_config)
    except SystemExit as e:
        # argparseãŒå¼•æ•°ã‚¨ãƒ©ãƒ¼ã§çµ‚äº†ã—ã‚ˆã†ã¨ã—ãŸå ´åˆã€ã“ã“ã§ã‚­ãƒ£ãƒƒãƒã—ã¦è¿½åŠ æƒ…å ±ã‚’æä¾›
        # (ã“ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯ã€å¼•æ•°ãŒä¸€éƒ¨ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆãªã©ã«å½¹ç«‹ã¤)
        if e.code != 0:
            print("\nå¼•æ•°ã®æŒ‡å®šã«èª¤ã‚ŠãŒã‚ã‚‹ã‚ˆã†ã§ã™ã€‚ä½¿ã„æ–¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        # parser.print_help() # å¿…è¦ã«å¿œã˜ã¦ãƒ˜ãƒ«ãƒ—ã‚’å†è¡¨ç¤º
import json
import os
import numpy as np
import argparse
import shutil

# å®šæ•°
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
config_dir = os.path.join(project_root, 'config')
log_dir = os.path.join(project_root, 'sigma_logs')

FAILURE_LOG_PATH = os.path.join(log_dir, "functor_consistency_failures.jsonl")
DEFAULT_SOURCE_DB_PATH = os.path.join(config_dir, "sigma_product_database_custom_ai_generated.json")
DEFAULT_STABILIZED_DB_PATH = os.path.join(config_dir, "sigma_product_database_stabilized.json")
ALPHA = 0.5 # è£œæ­£ä¿‚æ•°

def stabilize_database(source_db_path, stabilized_db_path):
    """å¤±æ•—ãƒ­ã‚°ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®‰å®šåŒ–ã•ã›ã‚‹"""
    print("ğŸŒ¿ å·®åˆ†è£œæ­£ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®‰å®šåŒ–ã‚’é–‹å§‹ã—ã¾ã™...")

    # 1. ã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€
    try:
        with open(source_db_path, 'r', encoding='utf-8') as f:
            db_data = json.load(f)
    except FileNotFoundError:
        print(f"â— ã‚¨ãƒ©ãƒ¼: ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_db_path}")
        return
    except json.JSONDecodeError:
        print(f"â— ã‚¨ãƒ©ãƒ¼: ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™: {source_db_path}")
        return

    # æ‰±ã„ã‚„ã™ã„ã‚ˆã†ã«IDã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã«å¤‰æ›
    db_dict = {item['id']: item for item in db_data}

    # 2. å¤±æ•—ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚“ã§è£œæ­£å‡¦ç†ã‚’è¡Œã†
    try:
        with open(FAILURE_LOG_PATH, 'r', encoding='utf-8') as f:
            failure_logs = [json.loads(line) for line in f]
    except FileNotFoundError:
        print(f"âœ… å¤±æ•—ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è£œæ­£ã¯ä¸è¦ã§ã™ã€‚ ({FAILURE_LOG_PATH})")
        # ãƒ­ã‚°ãŒãªã„å ´åˆã¯ã€ã‚½ãƒ¼ã‚¹ã‚’ãã®ã¾ã¾å®‰å®šç‰ˆã¨ã—ã¦ã‚³ãƒ”ãƒ¼ã™ã‚‹
        try:
            shutil.copyfile(source_db_path, stabilized_db_path)
            print(f"   ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ {stabilized_db_path} ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸã€‚")
        except IOError as e:
            print(f"\nâ— ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    if not failure_logs:
        print("âœ… å¤±æ•—ãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æ—¢ã«å®‰å®šçš„ã§ã™ã€‚")
        # ãƒ­ã‚°ãŒãªã„å ´åˆã¯ã€ã‚½ãƒ¼ã‚¹ã‚’ãã®ã¾ã¾å®‰å®šç‰ˆã¨ã—ã¦ã‚³ãƒ”ãƒ¼ã™ã‚‹
        try:
            shutil.copyfile(source_db_path, stabilized_db_path)
            print(f"   ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ {stabilized_db_path} ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸã€‚")
        except IOError as e:
            print(f"\nâ— ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    print(f"ğŸ“ {len(failure_logs)}ä»¶ã®å¤±æ•—ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚è£œæ­£å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")

    for log in failure_logs:
        image_name = log.get('image')
        if not image_name:
            continue

        item_id = os.path.splitext(image_name)[0]

        if item_id in db_dict:
            # è£œæ­£å¯¾è±¡ã®ãƒ™ã‚¯ãƒˆãƒ«
            original_vector = np.array(db_dict[item_id]['meaning_vector'])
            corrected_vector = original_vector.copy()

            # äºˆæœŸã›ãšå¤‰åŒ–ã—ãŸæ¬¡å…ƒã‚’ç‰¹å®š
            changed_indices = set(log.get('changed_indices', []))
            expected_indices = set(log.get('expected_indices', []))
            unexpected_indices = list(changed_indices - expected_indices)
            vector_diff = np.array(log.get('vector_diff', []))

            print(f"  ğŸ”§ è£œæ­£å¯¾è±¡: {item_id}")
            for i in unexpected_indices:
                diff = vector_diff[i]
                attenuation = diff * ALPHA # æ¸›è¡°é‡ã‚’è¨ˆç®—
                original_value = corrected_vector[i]
                corrected_value = max(0.0, original_value * (1 - attenuation))
                
                print(f"    - æ¬¡å…ƒ {i:<2}: å·®åˆ†={diff:.4f}, å€¤ã‚’ {original_value:.4f} -> {corrected_value:.4f} ã«è£œæ­£")
                corrected_vector[i] = corrected_value
            
            # è¾æ›¸å†…ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ›´æ–°
            db_dict[item_id]['meaning_vector'] = corrected_vector.tolist()
        else:
            print(f"  âš ï¸ è­¦å‘Š: å¤±æ•—ãƒ­ã‚°ã«è¨˜è¼‰ã®ID '{item_id}' ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    # 3. ä¿®æ­£å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™
    stabilized_db_data = list(db_dict.values())
    try:
        with open(stabilized_db_path, 'w', encoding='utf-8') as f:
            json.dump(stabilized_db_data, f, indent=2, ensure_ascii=False)
        print("\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å®‰å®šåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        print(f"   æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒ {stabilized_db_path} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    except IOError as e:
        print(f"\nâ— ã‚¨ãƒ©ãƒ¼: å®‰å®šåŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='å¤±æ•—ãƒ­ã‚°ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®‰å®šåŒ–ã•ã›ã¾ã™ã€‚\nå¤±æ•—ãƒ­ã‚°ãŒãªã„å ´åˆã¯ã€ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãã®ã¾ã¾å®‰å®šåŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚',
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument('--source', type=str, default=DEFAULT_SOURCE_DB_PATH,
                        help=f'ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¹ã€‚\n(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_SOURCE_DB_PATH})')
    parser.add_argument('--output', type=str, default=DEFAULT_STABILIZED_DB_PATH,
                        help=f'å®‰å®šåŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‡ºåŠ›ãƒ‘ã‚¹ã€‚\n(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_STABILIZED_DB_PATH})')
    args = parser.parse_args()

    stabilize_database(args.source, args.output)

import json
import numpy as np
import argparse
import os
import sys
from collections import deque

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç‰¹å®šã—ã€sys.pathã«è¿½åŠ 
script_dir = os.path.dirname(__file__)
project_root = os.path.abspath(os.path.join(script_dir, '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.dimension_loader import DimensionLoader
from src.personal_memory_graph import PersonalMemoryGraph
from src.information_metrics import compute_self_correlation_score

# DimensionLoaderã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
try:
    dimension_loader = DimensionLoader()
except Exception as e:
    print(f"â— DimensionLoaderã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    sys.exit(1)

def diagnose_unrelated(log_entry):
    """
    "Unrelated"ã¨åˆ†é¡ã•ã‚ŒãŸå˜ä¸€ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’è¨ºæ–­ã™ã‚‹ã€‚
    å„æ„å‘³è»¸ï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆãƒ™ã‚¯ãƒˆãƒ«ã®å¤§ãã•ï¼‰ã‚’è¨ˆç®—ã—ã€
    ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒä½ã„è»¸ã‚’ã€Œæƒ…å ±ä¸è¶³ã€ã®å€™è£œã¨ã—ã¦æŒ™ã’ã‚‹ã€‚
    """
    vector = np.array(log_entry.get('vector', []))
    if not vector.any():
        return ["ãƒ™ã‚¯ãƒˆãƒ«ãŒç©ºã§ã™ã€‚"]

    diagnoses = []
    
    # å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—
    layer_energies = {}
    # dimension_loaderã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ä»£ã‚ã‚Šã«ã€å®šç¾©æ¸ˆã¿ã®ãƒãƒƒãƒ—ã‚’ä½¿ç”¨
    for layer_name in dimension_loader._layer_map.keys():
        indices = dimension_loader.get_layer_indices(layer_name)
        if indices:
            layer_vector = vector[indices]
            # L2ãƒãƒ«ãƒ ã®2ä¹—ã§ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—
            energy = np.linalg.norm(layer_vector)**2
            layer_energies[layer_name] = energy

    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒå…¨ä½“ã®å¹³å‡ã«æ¯”ã¹ã¦è‘—ã—ãä½ã„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ç‰¹å®š
    if not layer_energies:
        return ["ãƒ¬ã‚¤ãƒ¤ãƒ¼æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"]
        
    total_energy = sum(layer_energies.values())
    avg_energy = total_energy / len(layer_energies) if len(layer_energies) > 0 else 0

    for layer, energy in layer_energies.items():
        # å¹³å‡ã®10%ä»¥ä¸‹ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã—ã‹ãªã„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ã€Œæƒ…å ±ä¸è¶³ã€ã¨è¦‹ãªã™
        if avg_energy > 0 and energy < avg_energy * 0.1:
            diagnoses.append(f"'{layer.capitalize()}'è»¸ã®æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ (ã‚¨ãƒãƒ«ã‚®ãƒ¼: {energy:.4f})")

    if not diagnoses:
        diagnoses.append("æ˜ç¢ºãªæƒ…å ±ä¸è¶³ã®è»¸ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ä½“çš„ã«æƒ…å ±ãŒæ›–æ˜§ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

    return diagnoses

def analyze_self_correlation_trends(memory_graph: PersonalMemoryGraph, window_size=10, deviation_threshold=2.0):
    """
    éå»ã®è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã€ç•°å¸¸ãªå¤‰å‹•ã‚’æ¤œå‡ºã™ã‚‹ã€‚
    """
    print("\n--- è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’é–‹å§‹ã—ã¾ã™ ---")
    all_memories = memory_graph.get_all_memories()
    if len(all_memories) < window_size + 1: # å±¥æ­´ã¨ç¾åœ¨ã®ã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒã™ã‚‹ãŸã‚
        print("  ååˆ†ãªå±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return

    self_correlation_scores = deque(maxlen=window_size) # æœ€æ–°ã®Nå€‹ã®ã‚¹ã‚³ã‚¢ã‚’ä¿æŒ
    anomalies = []

    for i, mem in enumerate(all_memories):
        score = mem.get("experience", {}).get("auxiliary_analysis", {}).get("self_correlation_score")
        if score is None:
            continue

        self_correlation_scores.append(score)

        if len(self_correlation_scores) == window_size:
            # ç§»å‹•å¹³å‡ã¨ç§»å‹•æ¨™æº–åå·®ã‚’è¨ˆç®—
            current_window_scores = np.array(list(self_correlation_scores))
            mean_sc = np.mean(current_window_scores)
            std_sc = np.std(current_window_scores)

            # ç¾åœ¨ã®ã‚¹ã‚³ã‚¢ãŒç§»å‹•å¹³å‡ã‹ã‚‰å¤§ããé€¸è„±ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if std_sc > 0:
                z_score = abs((score - mean_sc) / std_sc)
                if z_score >= deviation_threshold:
                    anomalies.append(f"  â— çµŒé¨“ {i+1} ({mem.get("experience", {}).get('source_image_name', "N/A')}): è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ãŒç•°å¸¸ ({score:.2f}, å¹³å‡: {mean_sc:.2f}, æ¨™æº–åå·®: {std_sc:.2f})")
            elif score != mean_sc: # std_sc == 0ã ãŒã‚¹ã‚³ã‚¢ãŒç•°ãªã‚‹å ´åˆ
                 anomalies.append(f"  â— çµŒé¨“ {i+1} ({mem.get("experience", {}).get('source_image_name', "N/A')}): è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ãŒç•°å¸¸ ({score:.2f}, éå»ã¯å¸¸ã« {mean_sc:.2f})")

    if anomalies:
        print("--- è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ã®ç•°å¸¸ãƒˆãƒ¬ãƒ³ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ ---")
        for anomaly in anomalies:
            print(anomaly)
    else:
        print("  è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ã®ç•°å¸¸ãƒˆãƒ¬ãƒ³ãƒ‰ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    print("--- ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’çµ‚äº†ã—ã¾ã™ ---")

def main():
    """
    ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ç…§åˆä¸èƒ½ï¼ˆUnrelatedï¼‰ãªçµæœã‚’è¨ºæ–­ã—ã€
    è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    """
    parser = argparse.ArgumentParser(description='SigmaSenseã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€ç…§åˆä¸èƒ½ãªçµæœã‚’è¨ºæ–­ã—ã¾ã™ã€‚')
    parser.add_argument('--log_file', type=str, default=os.path.join(project_root, "sigma_logs", "response_log.jsonl"),
                        help='åˆ†æå¯¾è±¡ã®.jsonlãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: sigma_logs/response_log.jsonl)')
    parser.add_argument('--memory_path', type=str, default=os.path.join(project_root, "sigma_logs", "personal_memory.jsonl"),
                        help='PersonalMemoryGraphã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: sigma_logs/personal_memory.jsonl)')
    parser.add_argument('--window_size', type=int, default=10,
                        help='è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«ä½¿ç”¨ã™ã‚‹ç§»å‹•å¹³å‡ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10)')
    parser.add_argument('--deviation_threshold', type=float, default=2.0,
                        help='è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ã®ç•°å¸¸ã¨è¦‹ãªã™æ¨™æº–åå·®ã®é–¾å€¤ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2.0)')
    args = parser.parse_args()

    print(f"ğŸ©º Nova Diagnoser: è¨ºæ–­ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    print(f"   ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {args.log_file}")
    print("="*70)

    unrelated_count = 0
    try:
        with open(args.log_file, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                try:
                    result = json.loads(line)
                    if result.get('ethics_passed') == False: # å€«ç†ãƒã‚§ãƒƒã‚¯ã§å¤±æ•—ã—ãŸã‚‚ã®ã‚’è¨ºæ–­å¯¾è±¡ã¨ã™ã‚‹
                        unrelated_count += 1
                        image_path = result.get('source_image_name', f'ãƒ­ã‚° {i+1}')
                        print(f"â—è¨ºæ–­å¯¾è±¡ (å€«ç†ãƒã‚§ãƒƒã‚¯å¤±æ•—): {image_path}")
                        
                        # ã“ã“ã§diagnose_unrelatedã‚’å‘¼ã³å‡ºã™ã“ã¨ã‚‚å¯èƒ½ã ãŒã€
                        # Novaã®å½¹å‰²æ‹¡å¼µã¨ã—ã¦ã€ã‚ˆã‚Šé«˜ãƒ¬ãƒ™ãƒ«ãªè¨ºæ–­ã‚’è¡Œã†
                        # ä¾‹: ã©ã®å€«ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå¤±æ•—ã—ãŸã‹ã€ãã®ç†ç”±ãªã©
                        ethics_log = result.get('ethics_log', [])
                        for entry in ethics_log:
                            if "Blocked" in entry or "Warning" in entry:
                                print(f"  -> {entry}")
                        print("-" * 50)

                except json.JSONDecodeError:
                    print(f"  â— line {i+1} ã®JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    except FileNotFoundError:
        print(f"â—ã‚¨ãƒ©ãƒ¼: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.log_file}")
    
    print("="*70)
    print(f"è¨ºæ–­å®Œäº†ã€‚{unrelated_count}ä»¶ã®å€«ç†ãƒã‚§ãƒƒã‚¯å¤±æ•—ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")

    # PersonalMemoryGraphã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è‡ªå·±ç›¸é–¢ã‚¹ã‚³ã‚¢ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè¡Œ
    memory_graph = PersonalMemoryGraph(args.memory_path)
    analyze_self_correlation_trends(memory_graph, args.window_size, args.deviation_threshold)


if __name__ == '__main__':
    main()